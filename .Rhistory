p <- ggsurvplot(fit.data, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
curves <- p$plot + facet_wrap(~Location)
curves
table(NewData)
table(NewData$Location)
library(xlsx)
library(ggplot2)
library(ggpubr)
library(survMisc)
library(survival)
library(survminer)
library(data.table)
library(grid)
library(gridExtra)
source("misc.R")
# Getting the data
AllData <- read.xlsx("data/DEAMS_SERENA.xlsx", 1, startRow = 6, colIndex = c(1, 4, 5, 6, 7, 9))
AllData$Type <- gsub('DEAMS - ', '', AllData$Type)
AllData$Severity <- gsub('Severity ', '', AllData$Severity)
AllData <- AllData[order(AllData$Submit.Date), ]
#===================================================================================
# Regex to get the locations and customer (after this should drop description)
# Who they are
AllData$Customer <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((C|c)ustomer:)).*?(?=\\w).*?(?=(\\s{2,3})|((E|e)mail:))", AllData$Description, perl = TRUE)), '[',1))
# Where they are
AllData$Location <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=Base:).*?(?=\\w).*?(?=(\\s{2,3})|((I|i)ssue:))", AllData$Description, perl = TRUE)), '[',1))
# tell them to stop complaining!
AllData$Phone <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((P|p)hone:)).*?(?=\\w).*?(?=(\\s{2,3})|((B|b)ase:))", AllData$Description, perl = TRUE)), '[',1))
#==================================================================================
#output to xlsx file (i need to look at the data again)
#write.xlsx(AllData, file = "data/output.xlsx", sheetName = "output2")
#drop all the description column after getting what we want
drops <- "Description"
AllData <- AllData[,!(names(AllData) %in% drops)]
#========================== grep commands to clean locations ====================
clean <- list(c("wp|wright", "trans|scott", "socom|mac", "san a|lack|jbsa", "trav", "minot", "mcgui|MDL", "mcconn", "dill", "scott", "max", "fair", "\\bgf\\b|forks", "ells", "dov", "dfas", "little|lra", "^$", "deams", "pope"), c("Wright P. AFB", "Scott AFB", "MacDill AFB", "JB SA", "Travis AFB", "Minot AFB", "JB MDL", "McConnell AFB", "MacDill AFB", "Scott AFB", "Maxwell AFB", "Fairchild AFB", "Grand F. AFB", "Ellsworth AFB", "Dover AFB", "DFAS", "Little R. AFB", "EMPTY", "DEAMS", "Pope AFB"))
# use custom function to clean the location column
AllData$Location <- clean.column(AllData$Location, clean)
#get all limestone, but not little rock
# but limestone is a town in OHIO!! alltogether need dfas
#grep("(\\bli\\b)|lime", AllData$Location, ignore.case = TRUE, value = TRUE)
#get little rock
#================================================================================
#=========== Create New Data frame ====================================================================================================
# subset data by selecting only rows where there are more than 3 occurences of each location
t <- table(AllData$Location)
NewData <- AllData[AllData$Location %in% names(t[t >= 3]), ]
# sort by location, and then by date
NewData <- NewData[order(NewData$Location, NewData$Submit.Date), ]
#=======================================================================================================================================
#======================================================= Time operations by group ======================================================
# Inter-failures using data.table package
#************** BUG WARNING: After using data.table, ********************
#normal ops for cumsums do not differentiate
#between EMPTY and ellsworth
#************** SOLUTION: calculate cumsums before using data.table *****
# cumulative time-to-fail
NewData$Time.To.Fail <- unlist(by(NewData, NewData$Location, function(x) difftime(x$Submit.Date, x$Submit.Date[1], units= "hours")))
# need to coerce for the package features to work
setDT(NewData)
setkey(NewData, Location)
NewData[ , Time.Between.Fails := c(0, difftime(Submit.Date[-1L], Submit.Date[-.N], units = "hours")), by = Location]
# coerce back to dataframe for normal operations
setDF(NewData)
table(NewData$Location)
t <- table(NewData$Location)
Small.Sample <- NewData[NewData$Location %in% names(t[(t >= 3) & (t < 11)]), ]
t <- table(NewData$Location)
Medium.Sample <- NewData[NewData$Location %in% names(t[(t >= 11) & (t < 60)]), ]
View(Small.Sample)
View(Medium.Sample)
names(t[(t >= 11) & (t < 60)])
names(t[(t >= 60) & (t < 300)])
names(t[(t >= 60) & (t < 300)]) & !("UNKNOWN")
names(t[(t >= 60) & (t < 300)])
names(t[(t >= 60) & (t < 300)]) != "UNKNOWN"
names(t[(t >= 60) & (t < 300)] != "UNKNOWN" )
names(t[(t >= 60) & (t < 300)])[!= "UNKNOWN"]
names(t[(t >= 60) & (t < 300) &(!= "UNKNOWN"]))
names(t[(t >= 60) & (t < 300) &(! "UNKNOWN"]))
names(t[(t >= 60) & (t < 300) &( t != "UNKNOWN"]))
names(t[(t >= 60) & (t < 300) & (t != "UNKNOWN")])
names(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN")
names(t[(t >= 60) & (t < 300)]) != "UNKNOWN"
Large.Sample <- NewData[NewData$Location %in% names(t[(t >= 60) & (t < 300)]) != "UNKNOWN", ]
View(Large.Sample)
Large.Sample <- NewData[NewData$Location %in% (names(t[(t >= 60) & (t < 300)]) != "UNKNOWN"), ]
View(Large.Sample)
names(t[(t >= 60) & (t < 300)]) != "UNKNOWN"
names(t[(t >= 60) & (t < 300)]!= "UNKNOWN")
names(t[(t >= 60) & (t < 300)])
t
t[1]
t[[1]]
t[[1]][1]
t[[1]][2]
names(t[1])
names(t[(t >= 60) & (t < 300)])
which(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN")
names(which(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN"))
which(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN", , useNames = TRUE)
names(t)
which(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN", useNames = TRUE)
t[which(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN")]
t[which(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN"), ]
t[,which(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN") ]
names(t[which(names(t[(t >= 60) & (t < 300)]) != "UNKNOWN")])
names(t[which( (names(t[(t >= 60) & (t < 300)])) != "UNKNOWN")])
names(t[which( (names(t[(t >= 60) & (t < 300)])))])
t <- table(NewData$Location)
names(t)
which(names(t) != "UNKNOWN")
t[which(names(t) != "UNKNOWN")]
names(t[which(names(t) != "UNKNOWN")])
names(t[ which(names(t[ (t >= 60) & (t < 300) ]) != "UNKNOWN") ])
names(t[ (t >= 60) & (t < 300) ])
names(t[ (t >= 60) & (t < 300), ])
names(t[ (t >= 60) & (t < 300) ])
names(t[ which( (names(t[ (t >= 60) & (t < 300)])) != "UNKNOWN") ])
Unknown.Sample <- NewData[NewData$Location == "UNKNOWN"]
Unknown.Sample <- NewData[NewData$Location %in% "UNKNOWN"]
Unknown.Sample <- NewData[NewData$Location == "UNKNOWN", ]
View(Unknown.Sample)
rm(list = ls())
library(xlsx)
library(ggplot2)
library(ggpubr)
library(survMisc)
library(survival)
library(survminer)
library(data.table)
library(grid)
library(gridExtra)
source("misc.R")
# Getting the data
AllData <- read.xlsx("data/DEAMS_SERENA.xlsx", 1, startRow = 6, colIndex = c(1, 4, 5, 6, 7, 9))
AllData$Type <- gsub('DEAMS - ', '', AllData$Type)
AllData$Severity <- gsub('Severity ', '', AllData$Severity)
AllData <- AllData[order(AllData$Submit.Date), ]
#===================================================================================
# Regex to get the locations and customer (after this should drop description)
# Who they are
AllData$Customer <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((C|c)ustomer:)).*?(?=\\w).*?(?=(\\s{2,3})|((E|e)mail:))", AllData$Description, perl = TRUE)), '[',1))
# Where they are
AllData$Location <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=Base:).*?(?=\\w).*?(?=(\\s{2,3})|((I|i)ssue:))", AllData$Description, perl = TRUE)), '[',1))
# tell them to stop complaining!
AllData$Phone <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((P|p)hone:)).*?(?=\\w).*?(?=(\\s{2,3})|((B|b)ase:))", AllData$Description, perl = TRUE)), '[',1))
#==================================================================================
#output to xlsx file (i need to look at the data again)
#write.xlsx(AllData, file = "data/output.xlsx", sheetName = "output2")
#drop all the description column after getting what we want
drops <- "Description"
AllData <- AllData[,!(names(AllData) %in% drops)]
#========================== grep commands to clean locations ====================
clean <- list(c("wp|wright", "trans|scott", "socom|mac", "san a|lack|jbsa", "trav", "minot", "mcgui|MDL", "mcconn", "dill", "scott", "max", "fair", "\\bgf\\b|forks", "ells", "dov", "dfas", "little|lra", "^$", "deams", "pope"), c("Wright P. AFB", "Scott AFB", "MacDill AFB", "JB SA", "Travis AFB", "Minot AFB", "JB MDL", "McConnell AFB", "MacDill AFB", "Scott AFB", "Maxwell AFB", "Fairchild AFB", "Grand F. AFB", "Ellsworth AFB", "Dover AFB", "DFAS", "Little R. AFB", "EMPTY", "DEAMS", "Pope AFB"))
# use custom function to clean the location column
AllData$Location <- clean.column(AllData$Location, clean)
#get all limestone, but not little rock
# but limestone is a town in OHIO!! alltogether need dfas
#grep("(\\bli\\b)|lime", AllData$Location, ignore.case = TRUE, value = TRUE)
#get little rock
#================================================================================
#=========== Create New Data frame ====================================================================================================
# subset data by selecting only rows where there are more than 3 occurences of each location
t <- table(AllData$Location)
NewData <- AllData[AllData$Location %in% names(t[t >= 3]), ]
# sort by location, and then by date
NewData <- NewData[order(NewData$Location, NewData$Submit.Date), ]
#=======================================================================================================================================
#======================================================= Time operations by group ======================================================
# Inter-failures using data.table package
#************** BUG WARNING: After using data.table, ********************
#normal ops for cumsums do not differentiate
#between EMPTY and ellsworth
#************** SOLUTION: calculate cumsums before using data.table *****
# cumulative time-to-fail
NewData$Time.To.Fail <- unlist(by(NewData, NewData$Location, function(x) difftime(x$Submit.Date, x$Submit.Date[1], units= "hours")))
# need to coerce for the package features to work
setDT(NewData)
setkey(NewData, Location)
NewData[ , Time.Between.Fails := c(0, difftime(Submit.Date[-1L], Submit.Date[-.N], units = "hours")), by = Location]
# coerce back to dataframe for normal operations
setDF(NewData)
t <- table(NewData$Location)
Unknown.Sample <- NewData[NewData$Location %in% "UNKNOWN"]
drops <- "UNKNOWN"
NewData <- NewData[,!(names(NewData) %in% drops)]
Small.Sample <- NewData[NewData$Location %in% names(t[(t >= 3) & (t < 11)]), ]
Medium.Sample <- NewData[NewData$Location %in% names(t[(t >= 11) & (t < 60)]), ]
Large.Sample <- NewData[NewData$Location %in% names(t[(t >= 60) & (t < 300)]), ]
View(Large.Sample)
View(Unknown.Sample)
t <- table(NewData$Location)
Unknown.Sample <- NewData[NewData$Location %in% "UNKNOWN", ]
drops <- "UNKNOWN"
NewData <- NewData[,!(names(NewData) %in% drops)]
Small.Sample <- NewData[NewData$Location %in% names(t[(t >= 3) & (t < 11)]), ]
Medium.Sample <- NewData[NewData$Location %in% names(t[(t >= 11) & (t < 60)]), ]
Large.Sample <- NewData[NewData$Location %in% names(t[(t >= 60) & (t < 300)]), ]
View(Unknown.Sample)
t <- table(NewData$Location)
Unknown.Sample <- NewData[NewData$Location %in% "UNKNOWN", ]
drops <- "UNKNOWN"
NewData <- NewData[,!(NewData$Location %in% drops)]
Small.Sample <- NewData[NewData$Location %in% names(t[(t >= 3) & (t < 11)]), ]
Medium.Sample <- NewData[NewData$Location %in% names(t[(t >= 11) & (t < 60)]), ]
Large.Sample <- NewData[NewData$Location %in% names(t[(t >= 60) & (t < 300)]), ]
t <- table(NewData$Location)
Unknown.Sample <- NewData[NewData$Location %in% "UNKNOWN", ]
drops <- "UNKNOWN"
NewData <- NewData[!(NewData$Location %in% drops), ]
names(NewData)
unique(NewData$Location)
Small.Sample <- NewData[NewData$Location %in% names(t[(t >= 3) & (t < 11)]), ]
Medium.Sample <- NewData[NewData$Location %in% names(t[(t >= 11) & (t < 60)]), ]
Large.Sample <- NewData[NewData$Location %in% names(t[(t >= 60) & (t < 300)]), ]
library(xlsx)
library(ggplot2)
library(ggpubr)
library(survMisc)
library(survival)
library(survminer)
library(data.table)
library(grid)
library(gridExtra)
source("misc.R")
# Getting the data
AllData <- read.xlsx("data/DEAMS_SERENA.xlsx", 1, startRow = 6, colIndex = c(1, 4, 5, 6, 7, 9))
AllData$Type <- gsub('DEAMS - ', '', AllData$Type)
AllData$Severity <- gsub('Severity ', '', AllData$Severity)
AllData <- AllData[order(AllData$Submit.Date), ]
#===================================================================================
# Regex to get the locations and customer (after this should drop description)
# Who they are
AllData$Customer <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((C|c)ustomer:)).*?(?=\\w).*?(?=(\\s{2,3})|((E|e)mail:))", AllData$Description, perl = TRUE)), '[',1))
# Where they are
AllData$Location <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=Base:).*?(?=\\w).*?(?=(\\s{2,3})|((I|i)ssue:))", AllData$Description, perl = TRUE)), '[',1))
# tell them to stop complaining!
AllData$Phone <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((P|p)hone:)).*?(?=\\w).*?(?=(\\s{2,3})|((B|b)ase:))", AllData$Description, perl = TRUE)), '[',1))
#==================================================================================
#output to xlsx file (i need to look at the data again)
#write.xlsx(AllData, file = "data/output.xlsx", sheetName = "output2")
#drop all the description column after getting what we want
drops <- "Description"
AllData <- AllData[,!(names(AllData) %in% drops)]
#========================== grep commands to clean locations ====================
clean <- list(c("wp|wright", "trans|scott", "socom|mac", "san a|lack|jbsa", "trav", "minot", "mcgui|MDL", "mcconn", "dill", "scott", "max", "fair", "\\bgf\\b|forks", "ells", "dov", "dfas", "little|lra", "^$", "deams", "pope"), c("Wright P. AFB", "Scott AFB", "MacDill AFB", "JB SA", "Travis AFB", "Minot AFB", "JB MDL", "McConnell AFB", "MacDill AFB", "Scott AFB", "Maxwell AFB", "Fairchild AFB", "Grand F. AFB", "Ellsworth AFB", "Dover AFB", "DFAS", "Little R. AFB", "EMPTY", "DEAMS", "Pope AFB"))
# use custom function to clean the location column
AllData$Location <- clean.column(AllData$Location, clean)
#get all limestone, but not little rock
# but limestone is a town in OHIO!! alltogether need dfas
#grep("(\\bli\\b)|lime", AllData$Location, ignore.case = TRUE, value = TRUE)
#get little rock
#================================================================================
#=========== Create New Data frame ====================================================================================================
# subset data by selecting only rows where there are more than 3 occurences of each location
t <- table(AllData$Location)
NewData <- AllData[AllData$Location %in% names(t[t >= 3]), ]
# sort by location, and then by date
NewData <- NewData[order(NewData$Location, NewData$Submit.Date), ]
#=======================================================================================================================================
#======================================================= Time operations by group ======================================================
# Inter-failures using data.table package
#************** BUG WARNING: After using data.table, ********************
#normal ops for cumsums do not differentiate
#between EMPTY and ellsworth
#************** SOLUTION: calculate cumsums before using data.table *****
# cumulative time-to-fail
NewData$Time.To.Fail <- unlist(by(NewData, NewData$Location, function(x) difftime(x$Submit.Date, x$Submit.Date[1], units= "hours")))
# need to coerce for the package features to work
setDT(NewData)
setkey(NewData, Location)
NewData[ , Time.Between.Fails := c(0, difftime(Submit.Date[-1L], Submit.Date[-.N], units = "hours")), by = Location]
# coerce back to dataframe for normal operations
setDF(NewData)
#=======================================================================================================================================
#========================= Not using these ========================================================================================
# #Make Time to Failure Column
# AllData$Time.to.Fail <- difftime(AllData$Submit.Date, AllData$Submit.Date[1], units = "hours")
# #Make Times Between Failure column
# AllData$Time.Between.Failure <- make.interFailures(AllData$Time.to.Fail)
#write(AllData$Time.to.Fail, "data/Failure_Times.txt", sep = "\n")
#write(AllData$Time.Between.Failure, "data/Time_Between_Failure.txt", sep = "\n")
#==================================================================================================================================
#===================== Subset by Sample Size ===============================================
t <- table(NewData$Location)
# Because the UNKNOWN location is largest and longest running sample
Unknown.Sample <- NewData[NewData$Location %in% "UNKNOWN", ]
drops <- "UNKNOWN"
NewData <- NewData[!(NewData$Location %in% drops), ]
Small.Sample <- NewData[NewData$Location %in% names(t[(t >= 3) & (t < 11)]), ]
Medium.Sample <- NewData[NewData$Location %in% names(t[(t >= 11) & (t < 60)]), ]
Large.Sample <- NewData[NewData$Location %in% names(t[(t >= 60) & (t < 300)]), ]
#Using survival packages to plot Kaplan Meier
Small.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = Small.Sample)
Small.gg <- ggsurvplot(Small.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
Small.km <- Small.gg$plot + facet_wrap(~Location)
Medium.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = Medium.Sample)
Medium.gg <- ggsurvplot(Medium.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
Medium.km <- Medium.gg$plot + facet_wrap(~Location)
Large.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = Large.Sample)
Large.gg <- ggsurvplot(Large.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
Large.km <- Large.gg$plot + facet_wrap(~Location)
Large.km
Medium.km
Small.km
UNKNOWN.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = UNKNOWN.Sample)
UNKNOWN.gg <- ggsurvplot(UNKNOWN.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
UNKNOWN.km <- UNKNOWN.gg$plot + facet_wrap(~Location)
library(xlsx)
library(ggplot2)
library(ggpubr)
library(survMisc)
library(survival)
library(survminer)
library(data.table)
library(grid)
library(gridExtra)
source("misc.R")
# Getting the data
AllData <- read.xlsx("data/DEAMS_SERENA.xlsx", 1, startRow = 6, colIndex = c(1, 4, 5, 6, 7, 9))
AllData$Type <- gsub('DEAMS - ', '', AllData$Type)
AllData$Severity <- gsub('Severity ', '', AllData$Severity)
AllData <- AllData[order(AllData$Submit.Date), ]
#===================================================================================
# Regex to get the locations and customer (after this should drop description)
# Who they are
AllData$Customer <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((C|c)ustomer:)).*?(?=\\w).*?(?=(\\s{2,3})|((E|e)mail:))", AllData$Description, perl = TRUE)), '[',1))
# Where they are
AllData$Location <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=Base:).*?(?=\\w).*?(?=(\\s{2,3})|((I|i)ssue:))", AllData$Description, perl = TRUE)), '[',1))
# tell them to stop complaining!
AllData$Phone <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((P|p)hone:)).*?(?=\\w).*?(?=(\\s{2,3})|((B|b)ase:))", AllData$Description, perl = TRUE)), '[',1))
#==================================================================================
#output to xlsx file (i need to look at the data again)
#write.xlsx(AllData, file = "data/output.xlsx", sheetName = "output2")
#drop all the description column after getting what we want
drops <- "Description"
AllData <- AllData[,!(names(AllData) %in% drops)]
#========================== grep commands to clean locations ====================
clean <- list(c("wp|wright", "trans|scott", "socom|mac", "san a|lack|jbsa", "trav", "minot", "mcgui|MDL", "mcconn", "dill", "scott", "max", "fair", "\\bgf\\b|forks", "ells", "dov", "dfas", "little|lra", "^$", "deams", "pope"), c("Wright P. AFB", "Scott AFB", "MacDill AFB", "JB SA", "Travis AFB", "Minot AFB", "JB MDL", "McConnell AFB", "MacDill AFB", "Scott AFB", "Maxwell AFB", "Fairchild AFB", "Grand F. AFB", "Ellsworth AFB", "Dover AFB", "DFAS", "Little R. AFB", "EMPTY", "DEAMS", "Pope AFB"))
# use custom function to clean the location column
AllData$Location <- clean.column(AllData$Location, clean)
#get all limestone, but not little rock
# but limestone is a town in OHIO!! alltogether need dfas
#grep("(\\bli\\b)|lime", AllData$Location, ignore.case = TRUE, value = TRUE)
#get little rock
#================================================================================
#=========== Create New Data frame ====================================================================================================
# subset data by selecting only rows where there are more than 3 occurences of each location
t <- table(AllData$Location)
NewData <- AllData[AllData$Location %in% names(t[t >= 3]), ]
# sort by location, and then by date
NewData <- NewData[order(NewData$Location, NewData$Submit.Date), ]
#=======================================================================================================================================
#======================================================= Time operations by group ======================================================
# Inter-failures using data.table package
#************** BUG WARNING: After using data.table, ********************
#normal ops for cumsums do not differentiate
#between EMPTY and ellsworth
#************** SOLUTION: calculate cumsums before using data.table *****
# cumulative time-to-fail
NewData$Time.To.Fail <- unlist(by(NewData, NewData$Location, function(x) difftime(x$Submit.Date, x$Submit.Date[1], units= "hours")))
# need to coerce for the package features to work
setDT(NewData)
setkey(NewData, Location)
NewData[ , Time.Between.Fails := c(0, difftime(Submit.Date[-1L], Submit.Date[-.N], units = "hours")), by = Location]
# coerce back to dataframe for normal operations
setDF(NewData)
#=======================================================================================================================================
#========================= Not using these ========================================================================================
# #Make Time to Failure Column
# AllData$Time.to.Fail <- difftime(AllData$Submit.Date, AllData$Submit.Date[1], units = "hours")
# #Make Times Between Failure column
# AllData$Time.Between.Failure <- make.interFailures(AllData$Time.to.Fail)
#write(AllData$Time.to.Fail, "data/Failure_Times.txt", sep = "\n")
#write(AllData$Time.Between.Failure, "data/Time_Between_Failure.txt", sep = "\n")
#==================================================================================================================================
#===================== Subset by Sample Size ===============================================
t <- table(NewData$Location)
# Because the UNKNOWN location is largest and longest running sample
Unknown.Sample <- NewData[NewData$Location %in% "UNKNOWN", ]
drops <- "UNKNOWN"
NewData <- NewData[!(NewData$Location %in% drops), ]
UNKNOWN.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = UNKNOWN.Sample)
UNKNOWN.gg <- ggsurvplot(UNKNOWN.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
UNKNOWN.km <- UNKNOWN.gg$plot + facet_wrap(~Location)
UNKNOWN.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = Unknown.Sample)
UNKNOWN.gg <- ggsurvplot(UNKNOWN.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
UNKNOWN.km <- UNKNOWN.gg$plot + facet_wrap(~Location)
UNKNOWN.km
UNKNOWN.gg
UNKNOWN.gg$plot
UNKNOWN.gg$plot %>% ggexport(filename = "data/full_scale.png", width = 1080, height = 900)
library(xlsx)
library(ggplot2)
library(ggpubr)
library(survMisc)
library(survival)
library(survminer)
library(data.table)
library(grid)
library(gridExtra)
source("misc.R")
# Getting the data
AllData <- read.xlsx("data/DEAMS_SERENA.xlsx", 1, startRow = 6, colIndex = c(1, 4, 5, 6, 7, 9))
AllData$Type <- gsub('DEAMS - ', '', AllData$Type)
AllData$Severity <- gsub('Severity ', '', AllData$Severity)
AllData <- AllData[order(AllData$Submit.Date), ]
#===================================================================================
# Regex to get the locations and customer (after this should drop description)
# Who they are
AllData$Customer <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((C|c)ustomer:)).*?(?=\\w).*?(?=(\\s{2,3})|((E|e)mail:))", AllData$Description, perl = TRUE)), '[',1))
# Where they are
AllData$Location <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=Base:).*?(?=\\w).*?(?=(\\s{2,3})|((I|i)ssue:))", AllData$Description, perl = TRUE)), '[',1))
# tell them to stop complaining!
AllData$Phone <- trimws(sapply(regmatches(AllData$Description, gregexpr("(?<=((P|p)hone:)).*?(?=\\w).*?(?=(\\s{2,3})|((B|b)ase:))", AllData$Description, perl = TRUE)), '[',1))
#==================================================================================
#output to xlsx file (i need to look at the data again)
#write.xlsx(AllData, file = "data/output.xlsx", sheetName = "output2")
#drop all the description column after getting what we want
drops <- "Description"
AllData <- AllData[,!(names(AllData) %in% drops)]
#========================== grep commands to clean locations ====================
clean <- list(c("wp|wright", "trans|scott", "socom|mac", "san a|lack|jbsa", "trav", "minot", "mcgui|MDL", "mcconn", "dill", "scott", "max", "fair", "\\bgf\\b|forks", "ells", "dov", "dfas", "little|lra", "^$", "deams", "pope"), c("Wright P. AFB", "Scott AFB", "MacDill AFB", "JB SA", "Travis AFB", "Minot AFB", "JB MDL", "McConnell AFB", "MacDill AFB", "Scott AFB", "Maxwell AFB", "Fairchild AFB", "Grand F. AFB", "Ellsworth AFB", "Dover AFB", "DFAS", "Little R. AFB", "EMPTY", "DEAMS", "Pope AFB"))
# use custom function to clean the location column
AllData$Location <- clean.column(AllData$Location, clean)
#get all limestone, but not little rock
# but limestone is a town in OHIO!! alltogether need dfas
#grep("(\\bli\\b)|lime", AllData$Location, ignore.case = TRUE, value = TRUE)
#get little rock
#================================================================================
#=========== Create New Data frame ====================================================================================================
# subset data by selecting only rows where there are more than 3 occurences of each location
t <- table(AllData$Location)
NewData <- AllData[AllData$Location %in% names(t[t >= 3]), ]
# sort by location, and then by date
NewData <- NewData[order(NewData$Location, NewData$Submit.Date), ]
#=======================================================================================================================================
#======================================================= Time operations by group ======================================================
# Inter-failures using data.table package
#************** BUG WARNING: After using data.table, ********************
#normal ops for cumsums do not differentiate
#between EMPTY and ellsworth
#************** SOLUTION: calculate cumsums before using data.table *****
# cumulative time-to-fail
NewData$Time.To.Fail <- unlist(by(NewData, NewData$Location, function(x) difftime(x$Submit.Date, x$Submit.Date[1], units= "hours")))
# need to coerce for the package features to work
setDT(NewData)
setkey(NewData, Location)
NewData[ , Time.Between.Fails := c(0, difftime(Submit.Date[-1L], Submit.Date[-.N], units = "hours")), by = Location]
# coerce back to dataframe for normal operations
setDF(NewData)
#=======================================================================================================================================
#========================= Not using these ========================================================================================
# #Make Time to Failure Column
# AllData$Time.to.Fail <- difftime(AllData$Submit.Date, AllData$Submit.Date[1], units = "hours")
# #Make Times Between Failure column
# AllData$Time.Between.Failure <- make.interFailures(AllData$Time.to.Fail)
#write(AllData$Time.to.Fail, "data/Failure_Times.txt", sep = "\n")
#write(AllData$Time.Between.Failure, "data/Time_Between_Failure.txt", sep = "\n")
#==================================================================================================================================
#===================== Subset by Sample Size ===============================================
t <- table(NewData$Location)
# Because the UNKNOWN location is largest and longest running sample
Unknown.Sample <- NewData[NewData$Location %in% "UNKNOWN", ]
drops <- "UNKNOWN"
SubData <- NewData[!(NewData$Location %in% drops), ]
Small.Sample <- SubData[SubData$Location %in% names(t[(t >= 3) & (t < 11)]), ]
Medium.Sample <- SubData[SubData$Location %in% names(t[(t >= 11) & (t < 60)]), ]
Large.Sample <- SubData[SubData$Location %in% names(t[(t >= 60) & (t < 300)]), ]
#===========================================================================================
#Using survival packages to plot Kaplan Meier
Full.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = NewData)
Full.gg <- ggsurvplot(Full.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
Full.km <- Full.gg$plot + facet_wrap(~Location)
UNKNOWN.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = Unknown.Sample)
UNKNOWN.gg <- ggsurvplot(UNKNOWN.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
UNKNOWN.km <- UNKNOWN.gg$plot + facet_wrap(~Location)
Small.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = Small.Sample)
Small.gg <- ggsurvplot(Small.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
Small.km <- Small.gg$plot + facet_wrap(~Location)
Medium.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = Medium.Sample)
Medium.gg <- ggsurvplot(Medium.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
Medium.km <- Medium.gg$plot + facet_wrap(~Location)
Large.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = Large.Sample)
Large.gg <- ggsurvplot(Large.Surv, fun = "event", conf.int = TRUE, color = "strata", ggtheme = theme_bw(), legend = "none")
Large.km <- Large.gg$plot + facet_wrap(~Location)
Full.km
Full.gg$plot %>% ggexport(filename = "data/full_scale.png", width = 1080, height = 900)
Full.gg
Full.km %>% ggexport(filename = "data/full_scale.png", width = 1080, height = 900)
UNKNOWN.km %>% ggexport(filename = "data/unknown.png", width = 900, height = 900)
UNKNOWN.gg$plot %>% ggexport(filename = "data/unknown.png", width = 900, height = 900)
UNKNOWN.gg$plot
UNKNOWN.gg$plot %>% ggexport(filename = "data/unknown.png", width = 900, height = 900)
UNKNOWN.gg$plot %>% ggexport(filename = "data/unknown_data.png", width = 900, height = 900)
Small.km %>% ggexport(filename = "data/unknown_data.png", width = 1080, height = 900)
Small.km %>% ggexport(filename = "data/smalls.png", width = 1080, height = 900)
UNKNOWN.gg$plot %>% ggexport(filename = "data/unknown_data.png", width = 900, height = 900)
Large.km %>% ggexport(filename = "data/smalls.png", width = 1080, height = 900)
Small.km %>% ggexport(filename = "data/smalls.png", width = 1080, height = 900)
Large.km %>% ggexport(filename = "data/large.png", width = 1080, height = 900)
Medium.km %>% ggexport(filename = "data/medium.png", width = 1080, height = 900)
Large.km %>% ggexport(filename = "data/large.png", width = 1080, height = 300)
Large.km %>% ggexport(filename = "data/large.png", width = 1080, height = 500)
Large.km %>% ggexport(filename = "data/large.png", width = 1080, height = 400)
Full.km %>% ggexport(filename = "data/full_scale.png", width = 1080, height = 900)
Full.gg %>% ggexport(filename = "data/full_overlay.png", width = 1080, height = 900)
Full.Surv <- survfit(Surv(Time.To.Fail) ~ Location, data = NewData)
Full.gg <- ggsurvplot(Full.Surv, fun = "event", conf.int = FALSE, color = "strata", ggtheme = theme_bw(), legend = "none")
Full.gg %>% ggexport(filename = "data/full_overlay_noConf.png", width = 1080, height = 900)
rm(list = ls())
